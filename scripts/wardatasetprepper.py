import pandas as pd
import numpy as np
import os

# Paths
BASE_DIR = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
DATA_DIR = os.path.join(BASE_DIR, "data")

class WarDatasetPrepper:
    def __init__(self, filepath):
        self.filepath = filepath
        self.df = None

    def load_and_clean(self):
        """
        Loads data, standardizes types, and fills structural nulls.
        """
        print("--- STEP 1: Loading dataset ---")
        # Load with date parsing
        self.df = pd.read_csv(self.filepath, parse_dates=['date'])
        
        # Sort rigorously: City first, then Date (CRUCIAL for temporal calculations)
        self.df = self.df.sort_values(by=['city_id', 'date'])
        
        # Logical Null Imputation:
        # If there's no terrain/fortification data, assume value 0 (irrelevant/open field)
        cols_to_zero = ['terrain_score', 'is_transport_hub', 'fortification_level', 
                        'symbolic_weight', 'population', 'geo_area_km2']
        # Use fillna only on columns that exist in the df
        cols_present = [c for c in cols_to_zero if c in self.df.columns]
        self.df[cols_present] = self.df[cols_present].fillna(0)
        
        print(f"Initial dataset loaded: {self.df.shape[0]} rows.")

    def filter_anomalies(self):
        """
        Removes the initial 'Maneuver Warfare' phase (Feb-April 2022)
        so the model learns 'Positional Warfare' logic.
        """
        print("--- STEP 2: Filtering Historical Anomalies ---")
        initial_rows = self.df.shape[0]
        
        # CUT: We only keep data from May 1, 2022
        # This removes the chaotic initial invasion and rapid retreats from Kyiv/Chernihiv.
        self.df = self.df[self.df['date'] >= '2022-05-01']
        
        dropped = initial_rows - self.df.shape[0]
        print(f"Rows removed (Chaos Phase): {dropped}")
        print(f"Remaining rows (Positional Phase): {self.df.shape[0]}")

    def create_momentum_features(self):
        """
        Generates inertia variables (front speed and acceleration).
        Key for 'Inertial', 'Conservative', etc. scenarios.
        """
        print("--- STEP 3: Calculating Front Dynamics (Momentum) ---")
        
        # Group by city so calculations don't mix different cities
        g = self.df.groupby('city_id')
        
        # DAILY DELTA: How much did the distance change today vs yesterday?
        # diff() negative means distance decreased (Russia approaches).
        # Multiply by -1 so: Positive Value = Russian Advance / Negative = Russian Retreat
        self.df['delta_dist_daily'] = g['dist_to_front_m'].diff() * -1
        
        # MOMENTUM (Trend):
        # Moving average of advance in the last 7 and 30 days.
        self.df['momentum_7d'] = g['delta_dist_daily'].transform(lambda x: x.rolling(7).mean())
        self.df['momentum_30d'] = g['delta_dist_daily'].transform(lambda x: x.rolling(30).mean())
        
        # Clean nulls generated by rolling (first 30 days of each city)
        cols_momentum = ['delta_dist_daily', 'momentum_7d', 'momentum_30d']
        self.df[cols_momentum] = self.df[cols_momentum].fillna(0)

    def create_targets(self):
        """
        Defines what the model should predict (Next day values).
        """
        print("--- STEP 4: Generating Targets (Objectives) ---")
        g = self.df.groupby('city_id')
        
        # Target A: How much will the front advance TOMORROW? (Regression)
        self.df['target_delta_dist_next'] = g['delta_dist_daily'].shift(-1)
        
        # Target B: What will the encirclement score be TOMORROW? (Regression)
        self.df['target_encirclement_next'] = g['encirclement_score'].shift(-1)
        
        # Target C: Will it be captured TOMORROW? (Classification)
        self.df['target_is_captured_next'] = g['is_captured'].shift(-1)
        
        # Important: Last rows of each city will have NaN in target (because there's no "tomorrow").
        # We remove them for training.
        self.df = self.df.dropna(subset=['target_delta_dist_next'])

    def assign_weights(self):
        """
        Assigns 'Sample Weights' to prevent the model from being lazy (laziness penalty).
        We give more importance to active zones and real combat.
        """
        print("--- STEP 5: Assigning Training Weights ---")
        
        # Base weight for quiet rear areas
        self.df['sample_weight'] = 1.0
        
        # RULE 1: Combat Zone (< 50km from front) -> Weight x10
        # The model must pay close attention here.
        mask_combat_zone = self.df['dist_to_front_m'] < 50000
        self.df.loc[mask_combat_zone, 'sample_weight'] = 10.0
        
        # RULE 2: Real Action (Front moved significantly yesterday) -> Weight x20
        # If there was movement (>100m), it's CRITICAL data for learning advance mechanics.
        mask_active_front = np.abs(self.df['delta_dist_daily']) > 100 
        self.df.loc[mask_active_front, 'sample_weight'] = 20.0
        
        # RULE 3: Strategic Cities -> Weight Multiplier x1.5
        if 'symbolic_weight' in self.df.columns:
            self.df.loc[self.df['symbolic_weight'] > 1, 'sample_weight'] *= 1.5

        print("Weights assigned. The model will prioritize active fronts.")

    def get_processed_data(self):
        return self.df

# --- SCRIPT EXECUTION ---
if __name__ == "__main__":
    input_path = os.path.join(DATA_DIR, 'dataset.csv')
    output_path = os.path.join(DATA_DIR, 'dataset_to_train.csv')

    processor = WarDatasetPrepper(input_path)

    processor.load_and_clean()          # 1. Load and clean
    processor.filter_anomalies()        # 2. Remove chaotic phase (Feb-Apr 2022)
    processor.create_momentum_features()# 3. Calculate velocities
    processor.create_targets()          # 4. Prepare what we're going to predict
    processor.assign_weights()          # 5. Assign importance to rows

    df_final = processor.get_processed_data()

    # Save the result ready for training
    df_final.to_csv(output_path, index=False)
    print(f"\nSUCCESS! Processed dataset saved as: {output_path}")
    print(f"Final dimensions: {df_final.shape}")